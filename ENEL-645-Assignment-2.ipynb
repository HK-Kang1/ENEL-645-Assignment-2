{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The code ran on the TALC cluster\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Define data directories\n",
    "data_dir = r\"/work/TALC/enel645_2025w/garbage_data/\"\n",
    "train_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Train\")\n",
    "val_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Val\")\n",
    "test_dir = os.path.join(data_dir, \"CVPR_2024_dataset_Test\")\n",
    "\n",
    "### IMAGE ###\n",
    "# Define transformations\n",
    "transform = {\n",
    "    \"train\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(), \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]), \n",
    "                                                                           \n",
    "    ]),\n",
    "    \"val\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "    \"test\": transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]),\n",
    "}\n",
    "### MODEL ###\n",
    "class CombinedClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(CombinedClassifier, self).__init__()\n",
    "        ## Image\n",
    "        self.mobile_net = models.mobilenet_v2(pretrained=True)\n",
    "\n",
    "        for param in self.mobile_net.features.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        in_features_img = self.mobile_net.classifier[1].in_features\n",
    "        self.mobile_net.classifier = nn.Identity()\n",
    "        \n",
    "        ## Text\n",
    "        self.distilbert = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "        hidden_size_text = self.distilbert.config.hidden_size\n",
    "\n",
    "        # Normalization Layer\n",
    "        self.image_norm = nn.LayerNorm(in_features_img)\n",
    "        self.text_norm = nn.LayerNorm(hidden_size_text)\n",
    "\n",
    "        ## FC Layers\n",
    "        self.fc1 = nn.Linear(in_features_img + hidden_size_text, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "\n",
    "    def forward(self, image, input_ids, attention_mask):\n",
    "        # Image\n",
    "        image_features = self.mobile_net(image)\n",
    "        image_features = self.image_norm(image_features)\n",
    "\n",
    "        # Text\n",
    "        text_features = self.distilbert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        text_features = text_features[:, 0]\n",
    "        text_features = self.text_norm(text_features)\n",
    "        \n",
    "        # Concatenate image and text features\n",
    "        combined_features = torch.cat((image_features, text_features), dim=1)\n",
    "\n",
    "        output = F.relu(self.fc1(combined_features))\n",
    "        output = self.dropout(output)\n",
    "        output = F.relu(self.fc2(output))\n",
    "        output = self.dropout(output)\n",
    "        output = self.fc3(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "# Extract text from file names as well as labels\n",
    "def read_text_files_with_labels(path):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    image_paths = []\n",
    "    class_folders = sorted(os.listdir(path))  \n",
    "    label_map = {class_name: idx for idx, class_name in enumerate(class_folders)}\n",
    "\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(path, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            file_names = os.listdir(class_path)\n",
    "            for file_name in file_names:\n",
    "                file_path = os.path.join(class_path, file_name)\n",
    "                if os.path.isfile(file_path):\n",
    "                    file_name_no_ext, _ = os.path.splitext(file_name)\n",
    "                    text = file_name_no_ext.replace('_', ' ')\n",
    "                    text_without_digits = re.sub(r'\\d+', '', text)\n",
    "                    texts.append(text_without_digits)\n",
    "                    labels.append(label_map[class_name])\n",
    "                    image_paths.append(file_path)\n",
    "\n",
    "    return np.array(texts), np.array(labels), np.array(image_paths)\n",
    "\n",
    "# Define your dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, texts, labels, tokenizer, max_len, transform):\n",
    "        self.image_paths = image_paths\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = datasets.folder.default_loader(self.image_paths[idx])\n",
    "        image = self.transform(image)\n",
    "\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'image': image,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Load and process datasets\n",
    "text_train, labels_train, image_paths_train = read_text_files_with_labels(train_dir)\n",
    "text_val, labels_val, image_paths_val = read_text_files_with_labels(val_dir)\n",
    "text_test, labels_test, image_paths_test = read_text_files_with_labels(test_dir)\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# Define dataset\n",
    "max_len = 24\n",
    "dataset_train = CustomDataset(image_paths_train, text_train, labels_train, tokenizer, max_len, transform[\"train\"])\n",
    "dataset_val = CustomDataset(image_paths_val, text_val, labels_val, tokenizer, max_len, transform[\"val\"])\n",
    "dataset_test = CustomDataset(image_paths_test, text_test, labels_test, tokenizer, max_len, transform[\"test\"])\n",
    "\n",
    "# Data loaders\n",
    "train_loader = DataLoader(dataset_train, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(dataset_test, batch_size=8, shuffle=False)\n",
    "\n",
    "dataloaders = {\n",
    "    \"train\": train_loader,\n",
    "    \"val\": val_loader,\n",
    "    \"test\": test_loader\n",
    "}\n",
    "\n",
    "# Training function\n",
    "def train(model, dataloader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in dataloader:\n",
    "        images = batch['image'].to(device)\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['label'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(images, input_ids, attention_mask)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, preds = torch.max(output, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate(model, dataloader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "\n",
    "            output = model(images, input_ids, attention_mask)\n",
    "            loss = criterion(output, labels)\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            _, preds = torch.max(output, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return total_loss / len(dataloader), accuracy\n",
    "\n",
    "def predict(model, dataloader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    predictions = []\n",
    "    with torch.no_grad():  # Disable gradient tracking\n",
    "        for batch in dataloader:\n",
    "            images = batch['image'].to(device)\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images, input_ids, attention_mask)\n",
    "\n",
    "            # Get predictions\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "            # Convert predictions to CPU and append to the list\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Model setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CombinedClassifier().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "best_loss = 1e+10\n",
    "EPOCHS = 5\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(EPOCHS):\n",
    "    train_loss, train_acc = train(model, dataloaders[\"train\"], optimizer, criterion, device)\n",
    "    print(f'Epoch {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}', flush=True)\n",
    "    \n",
    "    val_loss, val_acc = evaluate(model, dataloaders[\"val\"], criterion, device)\n",
    "    print(f'Epoch {epoch+1}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}', flush=True)\n",
    "    \n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "print(\"Training complete.\")\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "# Evaluation\n",
    "test_predictions = predict(model, dataloaders[\"test\"], device)\n",
    "print(f\"Accuracy:  {(test_predictions == labels_test).sum()/labels_test.size:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from slurm job\n",
    "\n",
    "Epoch 1, Train Loss: 0.5396, Train Acc: 0.8155\n",
    "Epoch 1, Val Loss: 0.3389, Val Acc: 0.8856\n",
    "\n",
    "Epoch 2, Train Loss: 0.2951, Train Acc: 0.9028\n",
    "Epoch 2, Val Loss: 0.3100, Val Acc: 0.8883\n",
    "\n",
    "Epoch 3, Train Loss: 0.2313, Train Acc: 0.9259\n",
    "Epoch 3, Val Loss: 0.3103, Val Acc: 0.8894\n",
    "\n",
    "Epoch 4, Train Loss: 0.1875, Train Acc: 0.9380\n",
    "Epoch 4, Val Loss: 0.3325, Val Acc: 0.8972\n",
    "\n",
    "Epoch 5, Train Loss: 0.1592, Train Acc: 0.9441\n",
    "Epoch 5, Val Loss: 0.3327, Val Acc: 0.9056\n",
    "\n",
    "Training complete.\n",
    "\n",
    "Accuracy:  0.8590\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
